{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keras Simple Augmentation using Image Data Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten, Conv2D, MaxPooling2D\n",
    "from keras.utils import np_utils\n",
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "(feature_train, target_train), (feature_test,target_test) = mnist.load_data()\n",
    "\n",
    "train_predictors = feature_train.reshape(feature_train.shape[0],28,28,1)\n",
    "test_predictors = feature_tetrain_generator = ImageDataGenerator(rotation_range=7,horizontal_flip=True,shear_range=0.2,height_shift_range=0.07,zoom_range=0.2)\n",
    "\n",
    "test_generator = ImageDataGenerator()st.reshape(feature_test.shape[0],28,28,1)\n",
    "\n",
    "train_predictors = train_predictors.astype('float32')\n",
    "test_predictors = test_predictors.astype('float32')\n",
    "\n",
    "train_predictors /= 255\n",
    "test_predictors /= 255\n",
    "\n",
    "train_classes = np_utils.to_categorical(target_train,10)\n",
    "test_classes = np_utils.to_categorical(target_test,10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's build a simple convolutional model to classify mnist digits using data augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = Sequential()\n",
    "\n",
    "\n",
    "\n",
    "classifier.add(Conv2D(32,(3,3),input_shape=(28,28,1),activation='relu'))\n",
    "\n",
    "classifier.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "classifier.add(Flatten()) \n",
    "\n",
    "\n",
    "classifier.add(Dense(units = 128,activation='relu'))\n",
    "\n",
    "\n",
    "classifier.add(Dense(units = 10,activation='softmax')) \n",
    "classifier.compile(loss='categorical_crossentropy', optimizer='adam',metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now it's the most important part the data generator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We'll use the ImageDataGenerator class from Keras, it is therad-safe so we can use multiprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator = ImageDataGenerator(rotation_range=7,horizontal_flip=True,shear_range=0.2,height_shift_range=0.07,zoom_range=0.2)\n",
    "\n",
    "test_generator = ImageDataGenerator()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now we fit the generators to generate new MNIST samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_database = train_generator.flow(train_predictors,train_classes, batch_size=128)\n",
    "\n",
    "test_database = test_generator.flow(test_predictors,test_classes, batch_size=128)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### And finally we can train the model using the generators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "469/468 [==============================] - 5s 11ms/step - loss: 0.5667 - acc: 0.8202 - val_loss: 0.1930 - val_acc: 0.9415\n",
      "Epoch 2/5\n",
      "469/468 [==============================] - 4s 8ms/step - loss: 0.2326 - acc: 0.9273 - val_loss: 0.1254 - val_acc: 0.9602\n",
      "Epoch 3/5\n",
      "469/468 [==============================] - 4s 8ms/step - loss: 0.1699 - acc: 0.9481 - val_loss: 0.0944 - val_acc: 0.9702\n",
      "Epoch 4/5\n",
      "469/468 [==============================] - 4s 8ms/step - loss: 0.1419 - acc: 0.9556 - val_loss: 0.0859 - val_acc: 0.9742\n",
      "Epoch 5/5\n",
      "469/468 [==============================] - 4s 8ms/step - loss: 0.1212 - acc: 0.9615 - val_loss: 0.0857 - val_acc: 0.9738\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fc58a9e3d68>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.fit_generator(train_database,steps_per_epoch = 60000/128,epochs=5,\n",
    "                         validation_data=test_database,\n",
    "                         validation_steps=10000/128, use_multiprocessing=True,workers=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
